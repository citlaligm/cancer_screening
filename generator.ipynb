{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "csv_path = 'fixed_labels.csv'\n",
    "data = pd.read_csv(csv_path,\n",
    "                         index_col = False)\n",
    "y_labels = []\n",
    "\n",
    "data.columns= ['filename', 'old_label', 'type']\n",
    "\n",
    "y_train = data[\"type\"]\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    y_labels.append(y_train[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Turn labels into numbers and apply One-Hot Encoding\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_labels)\n",
    "y_train = encoder.transform(y_labels)\n",
    "#y_test = encoder.transform(y_test)\n",
    "\n",
    "# Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "y_train = y_train.astype(np.float32)\n",
    "print(y_train.shape)\n",
    "data[\"one_hot\"]= list(y_train)\n",
    "#print(data[\"one_hot\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def resize_image(image):\n",
    "    col = 500\n",
    "    row = 500\n",
    "    image = cv2.resize(image,(col,row), interpolation=cv2.INTER_AREA)    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_train(image_name, type_cancer, one_hot):  \n",
    "    path_file = \"train/\"+type_cancer+\"/\"+image_name\n",
    "    #print(path_file)\n",
    "    image = mpimg.imread(path_file)\n",
    "    image = resize_image(image)\n",
    "    image = np.array(image)\n",
    "    #print(one_hot)\n",
    "    return image,one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_size_row = 500\n",
    "new_size_col = 500\n",
    "def generate_train_batch(data,batch_size = 4):\n",
    "    ## Generator for trainning data\n",
    "    batch_images = np.zeros((batch_size, new_size_row, new_size_col, 3))\n",
    "    batch_type = np.zeros(batch_size)\n",
    "    batch_type = []\n",
    "    \n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            i_line = np.random.randint(len(data))\n",
    "            image_name = data[\"filename\"][i_line]\n",
    "            type_cancer = data[\"type\"][i_line]            \n",
    "            one_hot = list(data[\"one_hot\"][i_line])   \n",
    "            x,y = preprocess_train(image_name, type_cancer, one_hot)\n",
    "            #print(type(y))\n",
    "            batch_images[i_batch] = x\n",
    "            batch_type.append(y)\n",
    "        \n",
    "        yield batch_images, np.array(batch_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#x_sample_batch,y_sample_batch = next(generate_train_batch(data))\n",
    "#plt.imshow(x_sample_batch[0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-ed273a928294>:61 in train_neural_netwrok.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 1 completed out of 2, with epoch_loss 1075843552.0\n"
     ]
    }
   ],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "n_classes = 3\n",
    "batch_size = 4 \n",
    "num_epochs = 2\n",
    "input_data_size = 750000\n",
    "\n",
    "\"\"\" place holder for input and output values \"\"\"\n",
    "x = tf.placeholder('float',[None,input_data_size])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "\"\"\" Model the neural network\"\"\"\n",
    "def neural_network_model(data):\n",
    "    \n",
    "    \"\"\"output = (input_data * weights) + biases\n",
    "\t\n",
    "\tW has a shape of [784, 10] because we want\n",
    "\tto multiply the 784-dimensional image vectors by it \n",
    "\tto produce 10-dimensional vectors of evidence for the difference classes.\n",
    "\t\n",
    "\tb has a shape of [10] so we can add it to the output.\"\"\"\n",
    "    \n",
    "    hidden_layer_1 = {\"weights\":tf.Variable(tf.random_normal([input_data_size,n_nodes_hl1])),\n",
    "                      \"biases\":tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "    hidden_layer_2 = {\"weights\":tf.Variable(tf.random_normal([n_nodes_hl1,n_nodes_hl2])),\n",
    "                      \"biases\":tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "    hidden_layer_3 = {\"weights\":tf.Variable(tf.random_normal([n_nodes_hl2,n_nodes_hl3])),\n",
    "                      \"biases\":tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "    output_layer = {\"weights\":tf.Variable(tf.random_normal([n_nodes_hl3,n_classes])),\n",
    "                      \"biases\":tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    \"\"\" For each neuron in hidden layer:\n",
    "        output = activation(sum((input*weight)) + biases)\n",
    "        Hidden layer 1 takes actual input data, add it's weight\n",
    "        and biases, and send the output to second layer and so on. \n",
    "        Output of hidden layer 3 will be fed to output layer \n",
    "\t\trelu - Activation funtion, Computes rectified linear: max(features, 0)\n",
    "    \"\"\"\n",
    "    output_hl1 = tf.add(tf.matmul(data,hidden_layer_1['weights']),hidden_layer_1['biases'])\n",
    "    output_hl1 = tf.nn.relu(output_hl1)\n",
    "    \n",
    "    output_hl2 = tf.add(tf.matmul(output_hl1,hidden_layer_2['weights']),hidden_layer_2['biases'])\n",
    "    output_hl2 = tf.nn.relu(output_hl2)\n",
    "    \n",
    "    output_hl3 = tf.add(tf.matmul(output_hl2,hidden_layer_3['weights']),hidden_layer_3['biases'])\n",
    "    output_hl3 = tf.nn.relu(output_hl3)\n",
    "    \n",
    "    \"\"\" For each neuron in output layer:\n",
    "        output = (input*weight) + biases\"\"\"\n",
    "    output = tf.add(tf.matmul(output_hl3,output_layer['weights']),output_layer['biases'])\n",
    "    \n",
    "    return output\n",
    "    \n",
    "def train_neural_netwrok(x):\n",
    "    prediction = neural_network_model(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "        \"\"\" Training the netwrok to optimize the weights \"\"\"\n",
    "        epoch_loss = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_x,epoch_y = next(generate_train_batch(data))\n",
    "            #print(epoch_x.shape, epoch_y.shape)\n",
    "            #epoch_x.flatten()\n",
    "            \n",
    "            epoch_x= epoch_x.reshape(4, -1)\n",
    "            epoch_y = epoch_y.reshape(4,-1)\n",
    "            #print(epoch_y)\n",
    "            _,c = sess.run([optimizer,cost], feed_dict={x:epoch_x,y:epoch_y})\n",
    "            epoch_loss += c\n",
    "        print (\"Epoch %s completed out of %s, with epoch_loss %s\" %(epoch,num_epochs,epoch_loss))\n",
    "        \n",
    "        \"\"\" \n",
    "        After optimizing weights, run them through our model,\n",
    "        and compare the prediction to actual label, and evaluate the\n",
    "        accuracy of all the test data\n",
    "        \"\"\"\n",
    "        correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        #print (\"Accuracy : %s\" %(accuracy.eval({x:mnist.test.images,y:mnist.test.labels})))\n",
    "\n",
    "train_neural_netwrok(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
